<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Negative Binomial Probability Distribution | railey.io</title>
    <link>https://railey.io/negative-binomial-probability-distribution/</link>
      <atom:link href="https://railey.io/negative-binomial-probability-distribution/index.xml" rel="self" type="application/rss+xml" />
    <description>Negative Binomial Probability Distribution</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Malcolm R. Railey 2020</copyright><lastBuildDate>Thu, 24 Dec 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://railey.io/images/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png</url>
      <title>Negative Binomial Probability Distribution</title>
      <link>https://railey.io/negative-binomial-probability-distribution/</link>
    </image>
    
    <item>
      <title>New - Maybe Not - Notes on Negative Binomials</title>
      <link>https://railey.io/negative-binomial-probability-distribution/new-maybe-not-notes-on-negative-binomials/</link>
      <pubDate>Thu, 24 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://railey.io/negative-binomial-probability-distribution/new-maybe-not-notes-on-negative-binomials/</guid>
      <description>
&lt;link href=&#34;https://railey.io/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://railey.io/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Wiki has it wrong – please confirm. A &lt;strong&gt;negative binomial distribution&lt;/strong&gt; is a discrete probability distribution that models the number of [failures] in a sequence of independent and identically distributed Bernoulli trials before a specified [fixed] number of [successes] … occurs (“Negative Binomial Distribution”, corrected).&lt;/p&gt;
&lt;p&gt;Suppose there is a sequence of independent Bernoulli trials. Thus, each trial has two potential outcomes called “success” and “failure”. In each trial the probability of success is &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; and of failure is &lt;span class=&#34;math inline&#34;&gt;\((1 − p)\)&lt;/span&gt;. We are observing this sequence until a predefined number &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; of [successes] have occurred. Then the random number of [failures] we have seen, &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, will have the negative binomial (or Pascal) distribution (“Negative Binomial Distribution”, corrected).&lt;/p&gt;
&lt;p&gt;The probability mass function (&lt;strong&gt;pmf&lt;/strong&gt;) of the negative binomial distribution is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
P(X = k \ | \ r,p) = { k+r-1 \choose r-1} p^r (1-p)^k 
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is the number of failures, &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is the specified number of successes, and &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the specified probability of success.&lt;/p&gt;
&lt;hr /&gt;

&lt;div class=&#34;definition&#34;&gt;
&lt;p&gt;&lt;span id=&#34;def:unnamed-chunk-1&#34; class=&#34;definition&#34;&gt;&lt;strong&gt;Definition 1  (Negative Binomial Probability Distribution)  &lt;/strong&gt;&lt;/span&gt;A random variable &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is said to have a &lt;em&gt;negative binomial probability distribution&lt;/em&gt; if and only if&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
P(X=k \ | \ r,p) = {k+r-1 \choose r-1 } p^r (1-p)^k
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is the number of failures, &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is the specified number of successes, and &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the specified probability of success.
&lt;/div&gt;

&lt;hr /&gt;

&lt;div class=&#34;definition&#34;&gt;
&lt;p&gt;&lt;span id=&#34;def:unnamed-chunk-2&#34; class=&#34;definition&#34;&gt;&lt;strong&gt;Definition 2  (Negative Binomial Probability Distribution)  &lt;/strong&gt;&lt;/span&gt;A random variable &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is said to have a &lt;em&gt;negative binomial probability distribution&lt;/em&gt; if and only if&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
\ \ \ \ P(Y=y \ | \ r,p) = {y-1 \choose r-1 } p^r (1-p)^{y-r}
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
y = r, r+1, r+2, ..., \text{ and } 0 \le p \le 1
\end{align}\]&lt;/span&gt;&lt;/p&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is the number of trials, &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is the given number of successes, and &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the given probability of success.
&lt;/div&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&#34;https://railey.io/negative-binomial-probability-distribution/2020-12-24-new-maybe-not-notes-on-negative-binomials/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;personal-notes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Personal Notes&lt;/h1&gt;
&lt;p&gt;The negative probability distribution is equivalent to the geometric distribution when the number of successes equals one. That is, a random variable with a negative binomial probability distribution originates from a context similar to that of a random variable with a geometric distribution:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The random variable is based on a series of independent Bernoulli TRIALS.&lt;/li&gt;
&lt;li&gt;Each Bernoulli trial has one of two possible outcomes: SUCCESS or FAILURE.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The geometric and negative binomial distributions differ as to their desired final outcome:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Geometric distribution: The random variable equals the total number of trials up to and including the first SUCCESS;&lt;/li&gt;
&lt;li&gt;Negative Binomial (&lt;strong&gt;NOT EXACTLY&lt;/strong&gt;): The random variable equals the total number of trials up to and including the &lt;span class=&#34;math inline&#34;&gt;\(n^{th}\)&lt;/span&gt; SUCCESS.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Not Exactly:&lt;/strong&gt; Clearly, a negative binomial distribution equals the geometric distribution when the &lt;span class=&#34;math inline&#34;&gt;\(Nth\)&lt;/span&gt; trial IS the &lt;span class=&#34;math inline&#34;&gt;\(1st\)&lt;/span&gt; TRIAL.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Another way to look at the &lt;strong&gt;pmf&lt;/strong&gt; is to arrange the sequence of trials into two Events &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;, where
the Event &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; contains all the trials up to but not including the last trial and Event &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; contains only the last trial. See &lt;strong&gt;Figure 1&lt;/strong&gt; below.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://railey.io/negative-binomial-distribution/example-2.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;&lt;strong&gt;Figure 1.&lt;/strong&gt; Separate the trials into two Events A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Event &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; contains the number of trials equal to the total number of failures &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; plus the total number of successes &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; minus one,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
N[A] = &amp;amp; k+r-1 \\\\[0.5em]
     = &amp;amp; k + (r-1) \\\\
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The probability of Event &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is the total probability of any combination of &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; failures and &lt;span class=&#34;math inline&#34;&gt;\(r-1\)&lt;/span&gt; successes,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
Pr[A] = {k+r-1 \choose r-1 } (1-p)^k p^{r-1}
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The combination denotes the total number of ways to choose &lt;span class=&#34;math inline&#34;&gt;\(k+r-1\)&lt;/span&gt; trials taken &lt;span class=&#34;math inline&#34;&gt;\(r-1\)&lt;/span&gt; at a time. Essentially, I have &lt;span class=&#34;math inline&#34;&gt;\(k+r-1\)&lt;/span&gt; trials, and then I am allocating &lt;span class=&#34;math inline&#34;&gt;\(r-1\)&lt;/span&gt; successes among those trials.&lt;/p&gt;
&lt;p&gt;And for any one of those combinations, I have the combined probability of the &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; independent failures, &lt;span class=&#34;math inline&#34;&gt;\((1-p)^k\)&lt;/span&gt;, times the combined probability of the &lt;span class=&#34;math inline&#34;&gt;\(r-1\)&lt;/span&gt; independent successes.&lt;/p&gt;
&lt;p&gt;The probability of Event &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; is simply&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
Pr[B] = p
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And because we assume these trials are independent, the total probability is simply&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align}
Pr[X=k] = &amp;amp; Pr[A] \cdot Pr[B] \\\\[1em]
        = &amp;amp; \left[ {k+r-1 \choose r-1 } (1-p)^k p^{r-1} \right] \cdot Pr[B] \\\\[1em]
        = &amp;amp; \left[ {k+r-1 \choose r-1 } (1-p)^k p^{r-1} \right] \cdot  p \\\\[1em]
        = &amp;amp; {k+r-1 \choose r-1 } (1-p)^k p^{r-1} \cdot p \\\\[1em]
        = &amp;amp; {k+r-1 \choose r-1 } (1-p)^k p^r
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;From (Wackerly et al., p.116), let us select fixed values for &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; and consider events &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;, where&lt;/p&gt;
&lt;p&gt;$
     A = \{  (y-1)  (r-1)  \}
$&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;$
     B = \{  y  \}
$&lt;/p&gt;
&lt;p&gt;Precisely because the events &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; are independent, we can say&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P[ A \cap B] = P[A] \times P[B]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Given a random variable &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; with a negative binomial probability distribution and the desired number of &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; TRIALS that yield SUCCESS, the probability &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt; that &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; will equal &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; trials is given by the expression:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P[Y=y] = {y-1 \choose r-1}p^rq^{y-r}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the probability of SUCCESS in a trial, &lt;span class=&#34;math inline&#34;&gt;\(q=1-p\)&lt;/span&gt; is the probability of FAILURE, &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is the total number of trials, and &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is the total number of trials that yield a SUCCESS.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;in-text-citations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;In-Text Citations&lt;/h3&gt;
&lt;p&gt;(Wackerly et al.)&lt;/p&gt;
&lt;p&gt;(“Negative Binomial Distribution”)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;Wackerly, Dennis D, et al. Mathematical Statistics with Applications. 2002. 6th ed., Belmont, Calif., Brooks-Cole, 2008.&lt;/p&gt;
&lt;p&gt;“Negative Binomial Distribution.” Wikipedia, 18 Dec. 2020, en.wikipedia.org/wiki/Negative_binomial_distribution. Accessed 22 Dec. 2020.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Old Notes on Negative Binomial Probability Distributions</title>
      <link>https://railey.io/negative-binomial-probability-distribution/old-notes-on-negative-binomial-probability-distributions/</link>
      <pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://railey.io/negative-binomial-probability-distribution/old-notes-on-negative-binomial-probability-distributions/</guid>
      <description>&lt;p&gt;A &lt;strong&gt;negative binomial distribution&lt;/strong&gt; is a discrete probability distribution that models the number of successes in a sequence  of independent and identically distributed Bernoulli trials before a specified [fixed] number of failures &amp;hellip; occurs (“Negative Binomial Distribution”).&lt;/p&gt;
&lt;p&gt;Suppose there is a sequence of independent Bernoulli trials. Thus, each trial has two potential outcomes called &amp;ldquo;success&amp;rdquo; and &amp;ldquo;failure&amp;rdquo;. In each trial the probability of success is $p$ and of failure is $(1 − p)$. We are observing this sequence until a predefined number $r$ of failures have occurred. Then the random number of successes we have seen, $X$, will have the negative binomial (or Pascal) distribution (“Negative Binomial Distribution”).&lt;/p&gt;
&lt;p&gt;The probability mass function (&lt;strong&gt;pmf&lt;/strong&gt;) of the negative binomial distribution is&lt;/p&gt;
&lt;p&gt;\begin{equation}
Pr[X = x] = { k+r-1 \choose r-1} (1-p)^k p ^ r
\end{equation}&lt;/p&gt;
&lt;p&gt;where $r$ is the number of successes, $k$ is the number of failures, and $p$ is the probability of success.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Another way to look at the &lt;strong&gt;pmf&lt;/strong&gt; is to arrange the sequence of trials into two Events $A$ and $B$, where
the Event $A$ contains all the trials up to but not including the last trial and Event $B$ contains only the last trial. See &lt;strong&gt;Figure 1&lt;/strong&gt; below.&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&#39;https://railey.io/negative-binomial-probability-distribution/old-notes-on-negative-binomial-probability-distributions/example-2.png&#39; alt=&#39;Separate the trials into two Events A and B.&#39; /&gt;
	&lt;figcaption&gt;&lt;strong&gt;Figure 1.&lt;/strong&gt; Separate the trials into two Events A and B.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Event $A$ contains the number of trials equal to the total number of failures $k$ plus the total number of successes $r$ minus one,&lt;/p&gt;
&lt;p&gt;\begin{align}
N[A] = &amp;amp; k+r-1 \\[0.5em]
= &amp;amp; k + (r-1) \\&lt;br&gt;
\end{align}&lt;/p&gt;
&lt;p&gt;The probability of Event $A$ is the total probability of any combination of $k$ failures and $r-1$ successes,&lt;/p&gt;
&lt;p&gt;\begin{equation}
Pr[A] = {k+r-1 \choose r-1 } (1-p)^k p^{r-1}
\end{equation}&lt;/p&gt;
&lt;p&gt;The combination denotes the total number of ways to choose $k+r-1$ trials taken $r-1$ at a time. Essentially, I have $k+r-1$ trials, and then I am allocating $r-1$ successes among those trials.&lt;/p&gt;
&lt;p&gt;And for any one of those combinations, I have the combined probability of the $k$ independent failures, $(1-p)^k$, times the combined probability of the $r-1$ independent successes.&lt;/p&gt;
&lt;p&gt;The probability of Event $B$ is simply&lt;/p&gt;
&lt;p&gt;\begin{equation}
Pr[B] = p
\end{equation}&lt;/p&gt;
&lt;p&gt;And because we assume these trials are independent, the total probability is simply&lt;/p&gt;
&lt;p&gt;\begin{align}
Pr[X=x] = &amp;amp; Pr[A] \cdot Pr[B] \\[1em]
= &amp;amp; \left[ {k+r-1 \choose r-1 } (1-p)^k p^{r-1} \right] \cdot Pr[B] \\[1em]
= &amp;amp; \left[ {k+r-1 \choose r-1 } (1-p)^k p^{r-1} \right] \cdot  p \\[1em]
= &amp;amp; {k+r-1 \choose r-1 } (1-p)^k p^{r-1} \cdot p \\[1em]
= &amp;amp; {k+r-1 \choose r-1 } (1-p)^k p^r
\end{align}&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{theorem,&#34;&gt;Here is a definition
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-{definition,&#34;&gt;Here is a definition
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;$$k+r-1$ trials to separate the failures and successes from the final success.&lt;/p&gt;
&lt;p&gt;Here, the expression $k+r-1$ refers to the total number of trials, to include the number of failures $k$ plus the number of successes minus one $r-1$. We subtract one here becauseConsider a sequence of independent Bernoulli trials. Here, the outcome of each trial is either a SUCCESS or FAILURE. Let the probability of success equal $p$ and of failure&lt;/p&gt;
&lt;p&gt;produces one of two results&lt;/p&gt;
&lt;p&gt;The negative probability distribution is equivalent to the geometric distribution when the number of successes equals one.&lt;/p&gt;
&lt;p&gt;A random variable with a &lt;marker&gt;negative binomial probability distribution&lt;/marker&gt; originates from a context similar to that of a random variable with a geometric distribution:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The random variable is based on a series of TRIALS.&lt;/li&gt;
&lt;li&gt;The outcome of any TRIAL equals exactly one of two results: SUCCESS or FAILURE.&lt;/li&gt;
&lt;li&gt;The outcome of every TRIAL is independent of any other TRIAL.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The geometric and negative binomial distributions differ as to their desired final outcome:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Geometric distribution: The random variable equals the total number of trials up to and including the first SUCCESS;&lt;/li&gt;
&lt;li&gt;Negative Binomial: The random variable equals the total number of trials up to and including the $n^{th}$ SUCCESS.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Clearly, a negative binomial distribution equals the geometric distribution when the $Nth$ trial IS the $1st$ TRIAL.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;From (Wackerly et al., p.116), let us select fixed values for $y$ and $r$ and consider events $A$ and $B$, where&lt;/p&gt;
&lt;p&gt;$
\ \ \ \ \ A = \{ \text{ the first } (y-1) \text{ trials contain } (r-1) \text{ successes } \}
$&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;$
\ \ \ \ \ B = \{ \text{ trial } y \text{ results in a success } \}
$&lt;/p&gt;
&lt;p&gt;Precisely because the events $A$ and $B$ are independent, we can say&lt;/p&gt;
&lt;p&gt;$$P[ A \cap B] = P[A] \times P[B]$$&lt;/p&gt;
&lt;p&gt;Given a random variable $Y$ with a negative binomial probability distribution and the desired number of $r$ TRIALS that yield SUCCESS, the probability $P$ that $Y$ will equal $y$ trials is given by the expression:&lt;/p&gt;
&lt;p&gt;$$P[Y=y] = {y-1 \choose r-1}p^rq^{y-r}$$&lt;/p&gt;
&lt;p&gt;where $p$ is the probability of SUCCESS in a trial, $q=1-p$ is the probability of FAILURE, $r$ is the total number of trials, and $y$ is the total number of trials that yield a SUCCESS.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://railey.io/images/negative-binomial-distribution-example-1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://railey.io/images/negative-binomial-distribution-example-1.png&#34; alt=&#34;This example shows y-1 trials for r-1 successes.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://railey.io/images/negative-binomial-distribution-example-1.png&#34;&gt;Example3 image&lt;/a&gt;&lt;/p&gt;


















&lt;figure id=&#34;figure-strongfigure-1strong-negative-binomial-distribution&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://railey.io/images/negative-binomial-distribution-example-1.png&#34; data-caption=&#34;&amp;lt;strong&amp;gt;Figure 1.&amp;lt;/strong&amp;gt; Negative Binomial Distribution&#34;&gt;


  &lt;img src=&#34;https://railey.io/images/negative-binomial-distribution-example-1.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;strong&gt;Figure 1.&lt;/strong&gt; Negative Binomial Distribution
  &lt;/figcaption&gt;


&lt;/figure&gt;



















&lt;figure id=&#34;figure-strongfigure-1strong-negative-binomial-distribution&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://railey.io/images/negative-binomial-distribution-example-1.png&#34; data-caption=&#34;&amp;lt;strong&amp;gt;Figure 1.&amp;lt;/strong&amp;gt; Negative Binomial Distribution&#34;&gt;


  &lt;img src=&#34;https://railey.io/images/negative-binomial-distribution-example-1.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;strong&gt;Figure 1.&lt;/strong&gt; Negative Binomial Distribution
  &lt;/figcaption&gt;


&lt;/figure&gt;



















&lt;figure id=&#34;figure-strongfigure-1strong-negative-binomial-distribution&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://railey.io/images/negative-binomial-distribution-example-1.png&#34; data-caption=&#34;&amp;lt;strong&amp;gt;Figure 1.&amp;lt;/strong&amp;gt; Negative Binomial Distribution.&#34;&gt;


  &lt;img src=&#34;https://railey.io/images/negative-binomial-distribution-example-1.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;strong&gt;Figure 1.&lt;/strong&gt; Negative Binomial Distribution.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;hr&gt;
&lt;h3 id=&#34;in-text-citations&#34;&gt;In-Text Citations&lt;/h3&gt;
&lt;p&gt;(Wackerly et al.)&lt;/p&gt;
&lt;p&gt;(“Negative Binomial Distribution”)&lt;/p&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;p&gt;Wackerly, Dennis D, et al. Mathematical Statistics with Applications. 2002. 6th ed., Belmont, Calif., Brooks-Cole, 2008.&lt;/p&gt;
&lt;p&gt;“Negative Binomial Distribution.” Wikipedia, 18 Dec. 2020, en.wikipedia.org/wiki/Negative_binomial_distribution. Accessed 22 Dec. 2020.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
